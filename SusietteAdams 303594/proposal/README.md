# Research Proposal

Introduction

Avaya Research Center is evaluating the housing market in the Greater Toronto Area using third-party datasets collected by external sources. This information will provide a better understanding of what drives housing prices.  The purpose of this project is to find fact based insights on meaningful patterns in the housing market. The stakes are high in the real estate industry. If potential home buyers evaluate their purchasing correctly they can have a bigger return on their investment when it’s time to resell. Make a bad decisions by not getting to know the neighbourhood history before purchasing can lead to a lost when trying to resell. With improved historic data decisions can be made based on facts and data collected. In the past, home builders relied on their gut and focus groups. Avaya was able to obtain a dataset containing house sale prices from Listing.Ca, Toronto Police Service (Public Safety Data Portal), and Simply Analytics (Income) for the surrounding Toronto area.  

Objectives

Determine factors that will influence home buyers the most for example crimes in the neighbourhood and their household income. Within the market, different amenities appeal to different consumer groups. Some consumers are first time buyers, they prioritize space for growing families, others are empty nesters looking to downsize. Everyone still wants their money to go further. The overall objective is to determine how does crime in neighborhoods affects housing cost other factors that affects or drives housing cost.

Problem Statement

Focusing on the areas that has the most crime activities and determining the correlation between the cost of the houses in those areas and the household income and try to factor in the level of education in those areas as well.

Data Sources

The datasets were gathered from several different third party websitessuch as the Toronto Public Safety Data Portal, Listing.Ca, Simply Analytics and.

Collection Method

Analysis Methods

Timeline

Week 1:

Signup for GitHub, research python libraries and data APIs. Start developing a topic area/dataset for inquiry.

Week 2:

Begin data collection, assembling methodology for Exploratory Data Analysis.
ETL work into data warehousing.
Begin exploring data and documenting issues/limitations/needs understanding needs/limitations regarding research question (might need to adjust question, scope, data, etc.).

Week 3:

Submission of EDA sprint (via GitHub/Moodle).
Collect/Augment/Refine project according to Sprint 1 findings.
Develop several analytical methodologies (these should be methods you are interested in learning – like Topic modelling or sentiment analysis, or social network analysis, etc.)

Week 4:

All data collection should be completed.
The methodology should be finalized.

Week 5

Submission of Sprint 2 to GitHub/. Includes codebase, report (brief), and plan for analysis.

Week 6

Start final sprint prepare for final submission.

Week 7

Work on final project.

Week 8

Final report – pdf/word doc
3-5 pages of background, research question, methodology, results, conclusion
GitHub Repo. 
Well documented – meaning someone who comes across it randomly should know exactly what it is, how to re-create it, and what your repo contains
Final notebooks/analysis/results.
Each sprint notebook documented, detailed, and refined.


Document Overview

The remainder of this document details the requirements, technical approach, expected results and project plan. This sections will describe the plan on providing a solution to the problem statement, and achieve the scope.
